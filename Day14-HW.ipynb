{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ce44393-3036-4c90-904f-1e85718f57fb",
   "metadata": {},
   "source": [
    "## Introduction to Data Science\n",
    "\n",
    "#### University of Redlands - DATA 101\n",
    "#### Prof: Joanna Bieri [joanna_bieri@redlands.edu](mailto:joanna_bieri@redlands.edu)\n",
    "#### [Class Website: data101.joannabieri.com](https://joannabieri.com/data101.html)\n",
    "\n",
    "---------------------------------------\n",
    "# Homework Day 14\n",
    "---------------------------------------\n",
    "\n",
    "GOALS:\n",
    "\n",
    "1. Reflect on Algorithmic bias\n",
    "2. Consider your role in Data Ethics\n",
    "3. Report on your reading.\n",
    "\n",
    "----------------------------------------------------------\n",
    "\n",
    "This homework has **3 questions** and **1 reading report**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c422e3-32b1-452f-89a8-2586784d3957",
   "metadata": {},
   "source": [
    "## Important Information\n",
    "\n",
    "- Email: [joanna_bieri@redlands.edu](mailto:joanna_bieri@redlands.edu)\n",
    "- Office Hours: Duke 209 <a href=\"https://joannabieri.com/schedule.html\"> Click Here for Joanna's Schedule</a>\n",
    "\n",
    "## Day 14 Assignment - same drill.\n",
    "\n",
    "1. Make sure you can **Fork** and **Clone** the Day14 repo from [Redlands-DATA101](https://github.com/Redlands-DATA101)\n",
    "2. Open the file Day14-HW.ipynb and start doing the problems.\n",
    "    * You can do these problems as you follow along with the lecture notes and video.\n",
    "3. Get as far as you can before class.\n",
    "4. Submit what you have so far **Commit** and **Push** to Git.\n",
    "5. Take the daily check in quiz on **Canvas**.\n",
    "7. Come to class with lots of questions!\n",
    "\n",
    "## If you start having trouble with git!!!\n",
    "\n",
    "Some people have reported that GIT is disappearing or giving errors on when they try to use it in Jupyter Lab. Here is another option for interacting with git:\n",
    "\n",
    "[Git Desktop](https://github.com/apps/desktop)\n",
    "\n",
    "If yous start having errors, try downloading this app. I can show you how to use it in class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fd0fc5-0e82-4265-a328-e906366c4907",
   "metadata": {},
   "source": [
    "## Report on your Data Ethics reading:\n",
    "\n",
    "**Your answers should be written as neatly as possible in Markdown cells**\n",
    "\n",
    "Your homework for today is all essay and written work. Make sure you respond to the three questions in the lecture:\n",
    "\n",
    "**Q1** What is your response to our discussion of bias in algorithms? Talk about the pluses and minuses of using algorithms to make decisions in our human world.\n",
    "\n",
    "**Q2**\n",
    "How do you train yourself to make the right decisions (or reduce the likelihood of accidentally making the wrong decisions) at those points?\n",
    "\n",
    "**Q3**\n",
    "How do you respond when you see bias in someones work? How could you take action to educate others?\n",
    "\n",
    "\n",
    "**Reading Report**\n",
    "\n",
    "Write a report about what you learned from your ethics reading exploration. For each book/article you read:\n",
    "\n",
    "1. Include a full proper reference to the book/article.\n",
    "   * BOOK: Author last name, First name. Book Title: Subtitle. Edition, Publisher, Year.\n",
    "   * ONLINE ARTICLE: Author last name, First name. Article Title. Website name, date accessed. html link.\n",
    "   * [MLA styles for citing other types of online work](https://style.mla.org/works-cited/citations-by-format/online-works/?gad_source=1)\n",
    "2. Write a summary in your own words what the book/article was about. Imagine telling your classmates about what they would learn by reading the article.\n",
    "3. Discuss your own reaction to the book/article. Did it have any effect on how you think about data and ethics? Do you agree with the author? What specific ideas really stood out to you?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf53176f-7926-4d4e-967c-5b5bbd011abe",
   "metadata": {},
   "source": [
    "#### Q1\n",
    "\n",
    "**What is your response to our discussion of bias in algorithms? Talk about the pluses and minuses of using algorithms to make decisions in our human world.**\n",
    "\n",
    "Algorithms have many benefits to our society and driving us towards progress. One of the most apparent impacts of algorithms is their ability to streamline and automize many processes. Computer algorithms allow these tasks to require less human effort and to be completed in a fraction of the time it would normally take a person. With more efficient systems, progression in society is expedited. Furthermore, algorithms have the potential to make well-educated predictions based on historical data. With no drastic changes in society, these projections are fairly accurate and are able to help prepare for the future. Another positive impact of algorithms is their ability to personalize experiences to the individual. By analyzing user data, they can gain insight into the individual to better recommend anything ranging from a movie to watch to a product to buy.\n",
    "\n",
    "Despite the positive aspects of algorithms, they have many dangers that will prove to be detrimental if left unchecked. A large issue with algorithms is that they train based on historical data, which is inherently biased due to the society we live in. This can include misrepresentation or lack of representation for minorities. Therefore, predictions and calculations may favor certain groups, typically those who have systemically been in power. This perpetuates certain stereotypes and power imbalances. Additionally, inaccuracy and misinformation from algorithms can be especially dangerous. It is easier to disprove a claim made by a human than a claim made by a computer. So, if an algorithm is inaccurate in its output, that misinformation may be accepted as true, since it is less work to accept a lie than decipher the truth. Making decisions based on flawed models has the potential to bring false results into reality, building a society based on misinformation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a527f22-684c-4aee-aa4d-afd435a9c996",
   "metadata": {},
   "source": [
    "#### Q2\n",
    "\n",
    "**How do you train yourself to make the right decisions (or reduce the likelihood of accidentally making the wrong decisions) at those points?**\n",
    "\n",
    "Determining the \"right\" decision is subjective and depends on the factors prioritized. But, I belive a \"right\" decision would be one based on true information. It is crucial to verify the validity of data prior to using it to come to a conclusion. The danger of making a misinformed decision is that it may hinge on an idea that is false, meaning the decision has no practicality in reality or may even be harmful. Gathering honest information can be difficult, especially since sources often have large biases. An important part of research is analyzing multiple perspectives to gain a more unbaised point of view, as it will be easier to weigh the arguments on both sides. Another aspect of data collection is staying up to date on the topic. Basing a decision on data collected in the 1900s has much less validity compared to a study performed a year ago. Being aware of these tenets of collecting valid information allows more informed decision making, which typically correlates to a \"right\" decision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7335bfa0-82c0-46d7-9734-f4300dedfa54",
   "metadata": {},
   "source": [
    "#### Q3\n",
    "\n",
    "**How do you respond when you see bias in someones work? How could you take action to educate others?**\n",
    "\n",
    "It can be difficult to confront someone about a posssible bias in their work, as it calls out their internalized biases as well as the validity of their work. My main fear in pointing out a bias would be that the creator would be offended and hurt by the accusation. However, in most academic settings, I would think that creators are more open to differing opinions and receiving feedback on where their work may be lacking. I usually am adverse to confrontation but in this case, I would bring up the idea of a bias gently, such as asking a question about a certain group that is misrepresented in their work. This would cause them to reconsider their work and possibly realize their bias without excessive push. If they still did not acknowledge a bias, I would consider a more direct approach, even if it made me uncomfortable. It is crucial to call out biases when we see them so that our future can attempt to fix historical biases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca89bb8-e1ea-4af6-aea6-faf8874deaf2",
   "metadata": {},
   "source": [
    "#### Reading Report\n",
    "O'Neil, Cathy. Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy. First edition, Crown Publishers, 2016.\n",
    "\n",
    "\"Weapons of Math Destruction\" by Cathy O'Neil explores the danger of implementing Big Data models in our society. Three of the main failures of these systems is their opaque methodology, biased data, and their ability to self-perpetuate.\n",
    "\n",
    "O'Neil emphasizes how many models do not share their algorithms, meaning their analysis is accepted without the public being able to verify its vaildity. The concealment of these models makes it difficult for those affected by them to fight back and achieve a fair result. Hidden models makes it easier for their creators to omit certain factors that are impactful on the results. For example, O'Neil discusses a model that scored teachers based on student performance on standardized testing, compared to their previous scores. Not only did this lead to fearful teachers helping students cheat, worsening the education of the child, but also quality teachers got fired by an unfair system. This model failed to take into account other important factors, such as struggles in the child's personal life. Overall, these models lack of transparency and selectivity of factors cause them to produce harmful results.\n",
    "\n",
    "The models O'Neil focuses on are built by a common denominator: historical data. It is extremely common for historical data to reflect the biases in society at the time. By training new algorithms on biased data, results and predictions for the future are skewed by the injustices of the past. Although these models require information to learn, reducing biases is crucial to create a fairer society.\n",
    "\n",
    "Although models are built on historical data, they self-perpetuate by learning from data influenced by the decisions they have made. O'Neil illustrates this concept through the recidivism model used in prison. Prisoners would take surveys that would determine their risk level. However, these surveys targeted minorities, even if they could not explicitly ask about race. So, minorities would be classified higher risk, causing them to stay in prison longer, have a harder time finding a job once out of prison, and eventually re-committing a crime. She explains how biased models come to conclusions that disproportionately attack some groups, such as minorities and women. Then, these minorities are placed in worse situations, where they have fewer options and must resort to certain riskier behaviors. This contributes to the data sets and is re-inputted into the models, affirming the models decision making. This toxic cycle keeps oppressed groups down while historically dominant groups stay on top.\n",
    "\n",
    "I found this book very interesting, especially how models grew in popularity from moneyball. It surprised me that systems that influence much of our lives today started from performance analyses for a sport. In our modern society, models have a large impact on crucial sectors, including finance and banking. This book helped open my eyes to how computer algorithms are not free from biases, as they take on the biases of the data inputted. I liked O'Neils points about how transparency regarding a model allows it to be gamed, yet it is also crucial to have a transparent model so it can be evaluated for biases. Overall, I found this book a great overview about how data must be utilized in an ethical way for the betterment of society.to you?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6faae4b-ce39-4695-a87f-99e40bda1322",
   "metadata": {},
   "source": [
    "\n",
    "-------------------------------------------------------\n",
    "\n",
    "## Further watching\n",
    "\n",
    "If you have time, really explore the world of data ethics. You could watch some of the videos linked from class.\n",
    "\n",
    "### Weapons of Math Destruction | Cathy O'Neil | Talks at Google\n",
    "\n",
    "{{< video https://www.youtube.com/watch?v=TQHs8SA1qpk >}}\n",
    "\n",
    "### Imagining a Future Free from the Algorithms of Oppression | Safiya Noble | ACL 2019\n",
    "\n",
    "{{< video https://www.youtube.com/watch?v=tNi_U1Bb1S0 >}}\n",
    "\n",
    "### Whats An Algorithm Got To Do With It\n",
    "\n",
    "{{< video https://www.youtube.com/watch?v=5zxDwA99soA >}}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
